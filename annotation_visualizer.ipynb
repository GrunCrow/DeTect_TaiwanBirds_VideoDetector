{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23c5d5d",
   "metadata": {},
   "source": [
    "# YOLO Annotation Visualizer\n",
    "\n",
    "This notebook visualizes bounding box annotations from the video annotation tool, showing:\n",
    "- Full image frames with bounding boxes drawn\n",
    "- Zoomed-in regions around each detection with 50px margins\n",
    "- Side-by-side comparison for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8f44",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import necessary libraries for loading images, parsing annotations, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e6b24",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the paths to your annotation output directory and configure visualization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7370954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the output directory from the annotation tool\n",
    "OUTPUT_DIR = \"G:\\2025-04-15_videos_annotated\"  # Change this to your output directory\n",
    "\n",
    "# Zoom margin (pixels around the detection)\n",
    "MARGIN = 50\n",
    "\n",
    "# Class mapping (should match the classes used in annotation)\n",
    "CLASSES = {\n",
    "    0: \"Bat\",\n",
    "    1: \"Bird\", \n",
    "    2: \"DragonFly\",\n",
    "    3: \"Drone\",\n",
    "    4: \"Plane\",\n",
    "    5: \"Other\"\n",
    "}\n",
    "\n",
    "# Color map for different classes (BGR format for OpenCV)\n",
    "CLASS_COLORS = {\n",
    "    0: (255, 0, 0),      # Bat - Blue\n",
    "    1: (0, 255, 0),      # Bird - Green\n",
    "    2: (0, 255, 255),    # DragonFly - Yellow\n",
    "    3: (255, 0, 255),    # Drone - Magenta\n",
    "    4: (255, 165, 0),    # Plane - Orange\n",
    "    5: (128, 128, 128)   # Other - Gray\n",
    "}\n",
    "\n",
    "# Verify paths exist\n",
    "images_dir = os.path.join(OUTPUT_DIR, \"images\")\n",
    "labels_dir = os.path.join(OUTPUT_DIR, \"labels\")\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Images directory exists: {os.path.exists(images_dir)}\")\n",
    "print(f\"Labels directory exists: {os.path.exists(labels_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8f276",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define functions to load annotations, draw bounding boxes, and extract zoomed regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e72433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation(label_path):\n",
    "    \"\"\"\n",
    "    Load YOLO format annotation from file.\n",
    "    \n",
    "    Returns: List of tuples (class_id, x_center, y_center, width, height) in normalized [0,1] format\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    bboxes.append((class_id, x_center, y_center, width, height))\n",
    "    return bboxes\n",
    "\n",
    "def normalized_to_pixel_coords(x_center, y_center, width, height, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Convert normalized YOLO coordinates to pixel coordinates.\n",
    "    \n",
    "    Returns: (x1, y1, x2, y2) - top-left and bottom-right corners\n",
    "    \"\"\"\n",
    "    x_center_px = x_center * img_width\n",
    "    y_center_px = y_center * img_height\n",
    "    width_px = width * img_width\n",
    "    height_px = height * img_height\n",
    "    \n",
    "    x1 = int(x_center_px - width_px / 2)\n",
    "    y1 = int(y_center_px - height_px / 2)\n",
    "    x2 = int(x_center_px + width_px / 2)\n",
    "    y2 = int(y_center_px + height_px / 2)\n",
    "    \n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def draw_bbox_on_image(image, bbox, class_id, thickness=2):\n",
    "    \"\"\"\n",
    "    Draw a single bounding box on image.\n",
    "    \n",
    "    Args:\n",
    "        image: OpenCV image (BGR)\n",
    "        bbox: Tuple (class_id, x_center, y_center, width, height) in normalized format\n",
    "        class_id: Class ID for the bounding box\n",
    "        thickness: Line thickness for drawing\n",
    "    \n",
    "    Returns: Image with bbox drawn\n",
    "    \"\"\"\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    class_id, x_center, y_center, width, height = bbox\n",
    "    \n",
    "    x1, y1, x2, y2 = normalized_to_pixel_coords(x_center, y_center, width, height, img_height, img_width)\n",
    "    \n",
    "    # Clamp to image bounds\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(img_width, x2)\n",
    "    y2 = min(img_height, y2)\n",
    "    \n",
    "    color = CLASS_COLORS.get(class_id, (255, 255, 255))\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # Add class label\n",
    "    label_text = f\"{CLASSES.get(class_id, 'Unknown')}\"\n",
    "    label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(image, (x1, y1 - label_size[1] - 4), (x1 + label_size[0], y1), color, -1)\n",
    "    cv2.putText(image, label_text, (x1, y1 - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    return image, (x1, y1, x2, y2)\n",
    "\n",
    "def extract_zoom_region(image, x1, y1, x2, y2, margin=50):\n",
    "    \"\"\"\n",
    "    Extract zoomed region around bounding box with margin.\n",
    "    \n",
    "    Args:\n",
    "        image: OpenCV image (BGR)\n",
    "        x1, y1, x2, y2: Bounding box coordinates in pixels\n",
    "        margin: Margin in pixels around the bbox\n",
    "    \n",
    "    Returns: Cropped image, clipped coordinates\n",
    "    \"\"\"\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    \n",
    "    # Add margin and clamp to image bounds\n",
    "    zoom_x1 = max(0, x1 - margin)\n",
    "    zoom_y1 = max(0, y1 - margin)\n",
    "    zoom_x2 = min(img_width, x2 + margin)\n",
    "    zoom_y2 = min(img_height, y2 + margin)\n",
    "    \n",
    "    cropped = image[zoom_y1:zoom_y2, zoom_x1:zoom_x2].copy()\n",
    "    \n",
    "    # Convert bbox coords relative to cropped image\n",
    "    rel_x1 = x1 - zoom_x1\n",
    "    rel_y1 = y1 - zoom_y1\n",
    "    rel_x2 = x2 - zoom_x1\n",
    "    rel_y2 = y2 - zoom_y1\n",
    "    \n",
    "    return cropped, (rel_x1, rel_y1, rel_x2, rel_y2)\n",
    "\n",
    "def get_annotated_images():\n",
    "    \"\"\"Get list of image files that have annotations.\"\"\"\n",
    "    images_dir = os.path.join(OUTPUT_DIR, \"images\")\n",
    "    labels_dir = os.path.join(OUTPUT_DIR, \"labels\")\n",
    "    \n",
    "    annotated_images = []\n",
    "    \n",
    "    if not os.path.exists(labels_dir):\n",
    "        return annotated_images\n",
    "    \n",
    "    # Find all label files\n",
    "    for label_file in os.listdir(labels_dir):\n",
    "        if label_file.endswith('.txt'):\n",
    "            image_file = label_file.replace('.txt', '.jpg')\n",
    "            image_path = os.path.join(images_dir, image_file)\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                annotated_images.append((image_path, label_path))\n",
    "    \n",
    "    return sorted(annotated_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f73695",
   "metadata": {},
   "source": [
    "## Load Annotation Data\n",
    "\n",
    "Find and list all annotated images with bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all annotated images\n",
    "annotated_images = get_annotated_images()\n",
    "\n",
    "print(f\"Found {len(annotated_images)} annotated images\")\n",
    "\n",
    "# Display summary\n",
    "if annotated_images:\n",
    "    print(\"\\nSample annotated images:\")\n",
    "    for i, (img_path, label_path) in enumerate(annotated_images[:5]):\n",
    "        filename = os.path.basename(img_path)\n",
    "        bboxes = load_annotation(label_path)\n",
    "        print(f\"  {i+1}. {filename} - {len(bboxes)} bounding box(es)\")\n",
    "else:\n",
    "    print(\"No annotated images found. Please check the OUTPUT_DIR path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425abcfe",
   "metadata": {},
   "source": [
    "## Visualize Annotations\n",
    "\n",
    "Display annotated images with full frames and zoomed regions side-by-side.\n",
    "\n",
    "**Instructions:**\n",
    "- Adjust the `START_IDX` and `NUM_VISUALIZE` variables below to view different annotations\n",
    "- Each row shows one annotated image with its bounding boxes\n",
    "- Left: Full frame with all bounding boxes drawn\n",
    "- Right: Zoomed region with 50px margin around each detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e05a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for visualization\n",
    "START_IDX = 0  # Start from which annotated image\n",
    "NUM_VISUALIZE = 5  # How many to visualize\n",
    "\n",
    "# Get the images to visualize\n",
    "images_to_show = annotated_images[START_IDX : START_IDX + NUM_VISUALIZE]\n",
    "\n",
    "print(f\"Visualizing {len(images_to_show)} images (indices {START_IDX}-{START_IDX + len(images_to_show) - 1})\")\n",
    "print(f\"Total annotated images available: {len(annotated_images)}\\n\")\n",
    "\n",
    "# Visualize each annotated image\n",
    "for img_idx, (image_path, label_path) in enumerate(images_to_show):\n",
    "    # Load image and annotation\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    bboxes = load_annotation(label_path)\n",
    "    \n",
    "    if not bboxes:\n",
    "        continue\n",
    "    \n",
    "    filename = os.path.basename(image_path)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Image {START_IDX + img_idx + 1}: {filename}\")\n",
    "    print(f\"Detections: {len(bboxes)}\")\n",
    "    \n",
    "    # Create figure for this image with subplots (one row per bbox)\n",
    "    num_bboxes = len(bboxes)\n",
    "    fig, axes = plt.subplots(num_bboxes, 2, figsize=(14, 5 * num_bboxes))\n",
    "    \n",
    "    # Handle single bbox case (axes won't be 2D)\n",
    "    if num_bboxes == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Draw full image with all bboxes\n",
    "    img_with_bboxes = img_rgb.copy()\n",
    "    bbox_pixel_coords = []\n",
    "    \n",
    "    for bbox_idx, bbox in enumerate(bboxes):\n",
    "        class_id = bbox[0]\n",
    "        img_with_bboxes, (x1, y1, x2, y2) = draw_bbox_on_image(img_with_bboxes, bbox, class_id, thickness=2)\n",
    "        bbox_pixel_coords.append((x1, y1, x2, y2, class_id))\n",
    "    \n",
    "    # Display full image on left column for each bbox\n",
    "    for bbox_idx, (x1, y1, x2, y2, class_id) in enumerate(bbox_pixel_coords):\n",
    "        ax_left = axes[bbox_idx, 0]\n",
    "        ax_left.imshow(img_with_bboxes)\n",
    "        ax_left.set_title(f\"Full Frame - Detection {bbox_idx + 1}/{num_bboxes}\\n({CLASSES.get(class_id, 'Unknown')})\", fontsize=10, fontweight='bold')\n",
    "        ax_left.axis('off')\n",
    "        \n",
    "        # Extract and display zoomed region on right\n",
    "        ax_right = axes[bbox_idx, 1]\n",
    "        zoomed_img, rel_coords = extract_zoom_region(img_rgb, x1, y1, x2, y2, margin=MARGIN)\n",
    "        zoomed_img_copy = zoomed_img.copy()\n",
    "        \n",
    "        # Draw bbox on zoomed image\n",
    "        rel_x1, rel_y1, rel_x2, rel_y2 = rel_coords\n",
    "        color = CLASS_COLORS.get(class_id, (255, 255, 255))\n",
    "        cv2.rectangle(zoomed_img_copy, (int(rel_x1), int(rel_y1)), (int(rel_x2), int(rel_y2)), color, 2)\n",
    "        \n",
    "        ax_right.imshow(zoomed_img_copy)\n",
    "        ax_right.set_title(f\"Zoomed (+{MARGIN}px margin) - Detection {bbox_idx + 1}/{num_bboxes}\", fontsize=10, fontweight='bold')\n",
    "        ax_right.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection details\n",
    "    for bbox_idx, bbox in enumerate(bboxes):\n",
    "        class_id, x_center, y_center, width, height = bbox\n",
    "        print(f\"  Detection {bbox_idx + 1}: {CLASSES.get(class_id, 'Unknown')} - Center: ({x_center:.4f}, {y_center:.4f}), Size: ({width:.4f}, {height:.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641d811",
   "metadata": {},
   "source": [
    "## Statistics and Summary\n",
    "\n",
    "Generate statistics about the annotations across all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics\n",
    "class_counts = {i: 0 for i in range(len(CLASSES))}\n",
    "total_bboxes = 0\n",
    "image_bbox_count = []\n",
    "\n",
    "for img_path, label_path in annotated_images:\n",
    "    bboxes = load_annotation(label_path)\n",
    "    image_bbox_count.append(len(bboxes))\n",
    "    total_bboxes += len(bboxes)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        class_id = bbox[0]\n",
    "        class_counts[class_id] += 1\n",
    "\n",
    "# Display statistics\n",
    "print(\"ANNOTATION STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total annotated images: {len(annotated_images)}\")\n",
    "print(f\"Total bounding boxes: {total_bboxes}\")\n",
    "print(f\"Average boxes per image: {total_bboxes / len(annotated_images) if annotated_images else 0:.2f}\")\n",
    "print(f\"Min boxes per image: {min(image_bbox_count) if image_bbox_count else 0}\")\n",
    "print(f\"Max boxes per image: {max(image_bbox_count) if image_bbox_count else 0}\")\n",
    "print()\n",
    "print(\"Detections by class:\")\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    count = class_counts[class_id]\n",
    "    percentage = (count / total_bboxes * 100) if total_bboxes > 0 else 0\n",
    "    print(f\"  {CLASSES.get(class_id, 'Unknown')}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Plot class distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of class distribution\n",
    "class_names = [CLASSES.get(i, f\"Class {i}\") for i in sorted(class_counts.keys())]\n",
    "class_values = [class_counts[i] for i in sorted(class_counts.keys())]\n",
    "colors = [CLASS_COLORS[i] for i in sorted(class_counts.keys())]\n",
    "# Convert BGR to RGB for matplotlib\n",
    "colors_rgb = [(b/255, g/255, r/255) for r, g, b in colors]\n",
    "\n",
    "ax1.bar(class_names, class_values, color=colors_rgb)\n",
    "ax1.set_title('Distribution of Annotations by Class', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Detections')\n",
    "ax1.set_xlabel('Class')\n",
    "for i, v in enumerate(class_values):\n",
    "    if v > 0:\n",
    "        ax1.text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Histogram of boxes per image\n",
    "ax2.hist(image_bbox_count, bins=range(0, max(image_bbox_count) + 2), edgecolor='black', color='steelblue')\n",
    "ax2.set_title('Distribution of Boxes per Image', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Number of Boxes per Image')\n",
    "ax2.set_ylabel('Number of Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualizations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
