{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e523e6",
   "metadata": {},
   "source": [
    "# Dataset CSV generator for video detector models\n",
    "\n",
    "This notebook processes annotated video frames and creates a CSV dataset file containing image paths and metadata for detector model training.\n",
    "\n",
    "**Features:**\n",
    "- Collects all annotated image paths\n",
    "- Extracts image dimensions and file metadata\n",
    "- Reads YOLO format labels and extracts annotation details\n",
    "- Generates comprehensive dataset CSV with metadata\n",
    "- Validates data integrity and provides statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ae790",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146e77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca59c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f713e63",
   "metadata": {},
   "source": [
    "## 2. Define Dataset Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fcf038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: /home/detect/DeTect_TaiwanBirds_VideoDetector\n",
      "Images Directory: /home/data/F2/videos/2025-05-14/images\n",
      "Labels Directory: /home/data/F2/videos/2025-05-14/labels\n",
      "Output CSV Path: /home/detect/DeTect_TaiwanBirds_VideoDetector/dataset/csvs/annotations.csv\n",
      "\n",
      "‚úì Images directory found: /home/data/F2/videos/2025-05-14/images\n",
      "  Found 10664 image files\n",
      "‚úì Labels directory found: /home/data/F2/videos/2025-05-14/labels\n",
      "  Found 892 label files\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "BASE_DIR = Path(r\"/home/detect/DeTect_TaiwanBirds_VideoDetector\")\n",
    "OUTPUT_DIR = Path(\"/home/data/F2/videos/2025-05-14/\")  # Change this to your output directory from annotation tool\n",
    "IMAGES_DIR = OUTPUT_DIR / \"images\"\n",
    "LABELS_DIR = OUTPUT_DIR / \"labels\"\n",
    "CSV_OUTPUT_PATH = BASE_DIR / \"dataset\" / \"csvs\" / \"annotations.csv\"\n",
    "\n",
    "# Verify directories exist\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Images Directory: {IMAGES_DIR}\")\n",
    "print(f\"Labels Directory: {LABELS_DIR}\")\n",
    "print(f\"Output CSV Path: {CSV_OUTPUT_PATH}\")\n",
    "print()\n",
    "\n",
    "# Check if directories exist\n",
    "if IMAGES_DIR.exists():\n",
    "    print(f\"‚úì Images directory found: {IMAGES_DIR}\")\n",
    "    image_count = len(list(IMAGES_DIR.glob(\"*.jpg\"))) + len(list(IMAGES_DIR.glob(\"*.png\")))\n",
    "    print(f\"  Found {image_count} image files\")\n",
    "else:\n",
    "    print(f\"‚úó Images directory not found: {IMAGES_DIR}\")\n",
    "    print(\"  Please update OUTPUT_DIR to point to your annotation output folder\")\n",
    "\n",
    "if LABELS_DIR.exists():\n",
    "    print(f\"‚úì Labels directory found: {LABELS_DIR}\")\n",
    "    label_count = len(list(LABELS_DIR.glob(\"*.txt\")))\n",
    "    print(f\"  Found {label_count} label files\")\n",
    "else:\n",
    "    print(f\"‚úó Labels directory not found: {LABELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85444a18",
   "metadata": {},
   "source": [
    "## 3. Load Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a9aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 7 classes:\n",
      "  0: Bat\n",
      "  1: Bird\n",
      "  2: Insect\n",
      "  3: Drone\n",
      "  4: Plane\n",
      "  5: Other\n",
      "  6: Unknown\n"
     ]
    }
   ],
   "source": [
    "# Load class mapping from CSV\n",
    "class_mapping = {}\n",
    "classes_csv = OUTPUT_DIR / \"classes.csv\"\n",
    "\n",
    "if classes_csv.exists():\n",
    "    with open(classes_csv, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                class_id = int(row[0])\n",
    "                class_name = row[1]\n",
    "                class_mapping[class_id] = class_name\n",
    "    print(f\"‚úì Loaded {len(class_mapping)} classes:\")\n",
    "    for class_id, class_name in sorted(class_mapping.items()):\n",
    "        print(f\"  {class_id}: {class_name}\")\n",
    "else:\n",
    "    print(f\"‚úó Classes CSV not found at {classes_csv}\")\n",
    "    print(\"  Using default class mapping\")\n",
    "    class_mapping = {0: \"Bat\", 1: \"Bird\", 2: \"Insect\", 3: \"Drone\", 4: \"Plane\", 5: \"Other\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2165dd",
   "metadata": {},
   "source": [
    "## 4. Collect Image Paths and Extract Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d7d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning images directory...\n",
      "  Processed 50/10664 images...\n",
      "  Processed 100/10664 images...\n",
      "  Processed 150/10664 images...\n",
      "  Processed 200/10664 images...\n",
      "  Processed 250/10664 images...\n",
      "  Processed 300/10664 images...\n",
      "  Processed 350/10664 images...\n",
      "  Processed 400/10664 images...\n",
      "  Processed 450/10664 images...\n",
      "  Processed 500/10664 images...\n",
      "  Processed 550/10664 images...\n",
      "  Processed 600/10664 images...\n",
      "  Processed 650/10664 images...\n",
      "  Processed 700/10664 images...\n",
      "  Processed 750/10664 images...\n",
      "  Processed 800/10664 images...\n",
      "  Processed 850/10664 images...\n",
      "  Processed 900/10664 images...\n",
      "  Processed 950/10664 images...\n",
      "  Processed 1000/10664 images...\n",
      "  Processed 1050/10664 images...\n",
      "  Processed 1100/10664 images...\n",
      "  Processed 1150/10664 images...\n",
      "  Processed 1200/10664 images...\n",
      "  Processed 1250/10664 images...\n",
      "  Processed 1300/10664 images...\n",
      "  Processed 1350/10664 images...\n",
      "  Processed 1400/10664 images...\n",
      "  Processed 1450/10664 images...\n",
      "  Processed 1500/10664 images...\n",
      "  Processed 1550/10664 images...\n",
      "  Processed 1600/10664 images...\n",
      "  Processed 1650/10664 images...\n",
      "  Processed 1700/10664 images...\n",
      "  Processed 1750/10664 images...\n",
      "  Processed 1800/10664 images...\n",
      "  Processed 1850/10664 images...\n",
      "  Processed 1900/10664 images...\n",
      "  Processed 1950/10664 images...\n",
      "  Processed 2000/10664 images...\n",
      "  Processed 2050/10664 images...\n",
      "  Processed 2100/10664 images...\n",
      "  Processed 2150/10664 images...\n",
      "  Processed 2200/10664 images...\n",
      "  Processed 2250/10664 images...\n",
      "  Processed 2300/10664 images...\n",
      "  Processed 2350/10664 images...\n",
      "  Processed 2400/10664 images...\n",
      "  Processed 2450/10664 images...\n",
      "  Processed 2500/10664 images...\n",
      "  Processed 2550/10664 images...\n",
      "  Processed 2600/10664 images...\n",
      "  Processed 2650/10664 images...\n",
      "  Processed 2700/10664 images...\n",
      "  Processed 2750/10664 images...\n",
      "  Processed 2800/10664 images...\n",
      "  Processed 2850/10664 images...\n",
      "  Processed 2900/10664 images...\n",
      "  Processed 2950/10664 images...\n",
      "  Processed 3000/10664 images...\n",
      "  Processed 3050/10664 images...\n",
      "  Processed 3100/10664 images...\n",
      "  Processed 3150/10664 images...\n",
      "  Processed 3200/10664 images...\n",
      "  Processed 3250/10664 images...\n",
      "  Processed 3300/10664 images...\n",
      "  Processed 3350/10664 images...\n",
      "  Processed 3400/10664 images...\n",
      "  Processed 3450/10664 images...\n",
      "  Processed 3500/10664 images...\n",
      "  Processed 3550/10664 images...\n",
      "  Processed 3600/10664 images...\n",
      "  Processed 3650/10664 images...\n",
      "  Processed 3700/10664 images...\n",
      "  Processed 3750/10664 images...\n",
      "  Processed 3800/10664 images...\n",
      "  Processed 3850/10664 images...\n",
      "  Processed 3900/10664 images...\n",
      "  Processed 3950/10664 images...\n",
      "  Processed 4000/10664 images...\n",
      "  Processed 4050/10664 images...\n",
      "  Processed 4100/10664 images...\n",
      "  Processed 4150/10664 images...\n",
      "  Processed 4200/10664 images...\n",
      "  Processed 4250/10664 images...\n",
      "  Processed 4300/10664 images...\n",
      "  Processed 4350/10664 images...\n",
      "  Processed 4400/10664 images...\n",
      "  Processed 4450/10664 images...\n",
      "  Processed 4500/10664 images...\n",
      "  Processed 4550/10664 images...\n",
      "  Processed 4600/10664 images...\n",
      "  Processed 4650/10664 images...\n",
      "  Processed 4700/10664 images...\n",
      "  Processed 4750/10664 images...\n",
      "  Processed 4800/10664 images...\n",
      "  Processed 4850/10664 images...\n",
      "  Processed 4900/10664 images...\n",
      "  Processed 4950/10664 images...\n",
      "  Processed 5000/10664 images...\n",
      "  Processed 5050/10664 images...\n",
      "  Processed 5100/10664 images...\n",
      "  Processed 5150/10664 images...\n",
      "  Processed 5200/10664 images...\n",
      "  Processed 5250/10664 images...\n",
      "  Processed 5300/10664 images...\n",
      "  Processed 5350/10664 images...\n",
      "  Processed 5400/10664 images...\n",
      "  Processed 5450/10664 images...\n",
      "  Processed 5500/10664 images...\n",
      "  Processed 5550/10664 images...\n",
      "  Processed 5600/10664 images...\n",
      "  Processed 5650/10664 images...\n",
      "  Processed 5700/10664 images...\n",
      "  Processed 5750/10664 images...\n",
      "  Processed 5800/10664 images...\n",
      "  Processed 5850/10664 images...\n",
      "  Processed 5900/10664 images...\n",
      "  Processed 5950/10664 images...\n",
      "  Processed 6000/10664 images...\n",
      "  Processed 6050/10664 images...\n",
      "  Processed 6100/10664 images...\n",
      "  Processed 6150/10664 images...\n",
      "  Processed 6200/10664 images...\n",
      "  Processed 6250/10664 images...\n",
      "  Processed 6300/10664 images...\n",
      "  Processed 6350/10664 images...\n",
      "  Processed 6400/10664 images...\n",
      "  Processed 6450/10664 images...\n",
      "  Processed 6500/10664 images...\n",
      "  Processed 6550/10664 images...\n",
      "  Processed 6600/10664 images...\n",
      "  Processed 6650/10664 images...\n",
      "  Processed 6700/10664 images...\n",
      "  Processed 6750/10664 images...\n",
      "  Processed 6800/10664 images...\n",
      "  Processed 6850/10664 images...\n",
      "  Processed 6900/10664 images...\n",
      "  Processed 6950/10664 images...\n",
      "  Processed 7000/10664 images...\n",
      "  Processed 7050/10664 images...\n",
      "  Processed 7100/10664 images...\n",
      "  Processed 7150/10664 images...\n",
      "  Processed 7200/10664 images...\n",
      "  Processed 7250/10664 images...\n",
      "  Processed 7300/10664 images...\n",
      "  Processed 7350/10664 images...\n",
      "  Processed 7400/10664 images...\n",
      "  Processed 7450/10664 images...\n",
      "  Processed 7500/10664 images...\n",
      "  Processed 7550/10664 images...\n",
      "  Processed 7600/10664 images...\n",
      "  Processed 7650/10664 images...\n",
      "  Processed 7700/10664 images...\n",
      "  Processed 7750/10664 images...\n",
      "  Processed 7800/10664 images...\n",
      "  Processed 7850/10664 images...\n",
      "  Processed 7900/10664 images...\n",
      "  Processed 7950/10664 images...\n",
      "  Processed 8000/10664 images...\n",
      "  Processed 8050/10664 images...\n",
      "  Processed 8100/10664 images...\n",
      "  Processed 8150/10664 images...\n",
      "  Processed 8200/10664 images...\n",
      "  Processed 8250/10664 images...\n",
      "  Processed 8300/10664 images...\n",
      "  Processed 8350/10664 images...\n",
      "  Processed 8400/10664 images...\n",
      "  Processed 8450/10664 images...\n",
      "  Processed 8500/10664 images...\n",
      "  Processed 8550/10664 images...\n",
      "  Processed 8600/10664 images...\n",
      "  Processed 8650/10664 images...\n",
      "  Processed 8700/10664 images...\n",
      "  Processed 8750/10664 images...\n",
      "  Processed 8800/10664 images...\n",
      "  Processed 8850/10664 images...\n",
      "  Processed 8900/10664 images...\n",
      "  Processed 8950/10664 images...\n",
      "  Processed 9000/10664 images...\n",
      "  Processed 9050/10664 images...\n",
      "  Processed 9100/10664 images...\n",
      "  Processed 9150/10664 images...\n",
      "  Processed 9200/10664 images...\n",
      "  Processed 9250/10664 images...\n",
      "  Processed 9300/10664 images...\n",
      "  Processed 9350/10664 images...\n",
      "  Processed 9400/10664 images...\n",
      "  Processed 9450/10664 images...\n",
      "  Processed 9500/10664 images...\n",
      "  Processed 9550/10664 images...\n",
      "  Processed 9600/10664 images...\n",
      "  Processed 9650/10664 images...\n",
      "  Processed 9700/10664 images...\n",
      "  Processed 9750/10664 images...\n",
      "  Processed 9800/10664 images...\n",
      "  Processed 9850/10664 images...\n",
      "  Processed 9900/10664 images...\n",
      "  Processed 9950/10664 images...\n",
      "  Processed 10000/10664 images...\n",
      "  Processed 10050/10664 images...\n",
      "  Processed 10100/10664 images...\n",
      "  Processed 10150/10664 images...\n",
      "  Processed 10200/10664 images...\n",
      "  Processed 10250/10664 images...\n",
      "  Processed 10300/10664 images...\n",
      "  Processed 10350/10664 images...\n",
      "  Processed 10400/10664 images...\n",
      "  Processed 10450/10664 images...\n",
      "  Processed 10500/10664 images...\n",
      "  Processed 10550/10664 images...\n",
      "  Processed 10600/10664 images...\n",
      "  Processed 10650/10664 images...\n",
      "\n",
      "‚úì Collected metadata for 10664 images\n"
     ]
    }
   ],
   "source": [
    "def extract_label_info(label_path):\n",
    "    \"\"\"Extract information from YOLO format label file\"\"\"\n",
    "    num_objects = 0\n",
    "    classes_present = set()\n",
    "    annotations = []\n",
    "    \n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    \n",
    "                    num_objects += 1\n",
    "                    classes_present.add(class_mapping.get(class_id, f\"Unknown_{class_id}\"))\n",
    "                    annotations.append({\n",
    "                        'class_id': class_id,\n",
    "                        'class_name': class_mapping.get(class_id, f\"Unknown_{class_id}\"),\n",
    "                        'x_center': x_center,\n",
    "                        'y_center': y_center,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "    \n",
    "    return num_objects, list(classes_present), annotations\n",
    "\n",
    "# Collect all dataset information\n",
    "dataset_rows = []\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
    "\n",
    "print(\"Scanning images directory...\")\n",
    "image_files = sorted([f for f in IMAGES_DIR.iterdir() if f.suffix in image_extensions])\n",
    "\n",
    "for idx, img_path in enumerate(image_files):\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(image_files)} images...\")\n",
    "    \n",
    "    # Get image metadata\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        img_format = img.format\n",
    "        file_size_kb = img_path.stat().st_size / 1024\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not read image {img_path}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Get corresponding label information\n",
    "    label_path = LABELS_DIR / (img_path.stem + \".txt\")\n",
    "    num_targets, classes_present, annotations = extract_label_info(label_path)\n",
    "    \n",
    "    # Create relative path for CSV\n",
    "    try:\n",
    "        rel_path = img_path.relative_to(BASE_DIR)\n",
    "    except ValueError:\n",
    "        rel_path = img_path\n",
    "    \n",
    "    # Extract video name and frame number from filename (assuming format: videoname_framenumber.jpg)\n",
    "    filename_parts = img_path.stem.rsplit('_', 1)\n",
    "    if len(filename_parts) == 2:\n",
    "        video_name = filename_parts[0]\n",
    "        try:\n",
    "            frame_number = int(filename_parts[1])\n",
    "        except ValueError:\n",
    "            video_name = img_path.stem\n",
    "            frame_number = -1\n",
    "    else:\n",
    "        video_name = img_path.stem\n",
    "        frame_number = -1\n",
    "    \n",
    "    # Create row for dataset\n",
    "    row = {\n",
    "        'image_path': str(rel_path),\n",
    "        'image_width': img_width,\n",
    "        'image_height': img_height,\n",
    "        'image_format': img_format,\n",
    "        'num_targets': num_targets,\n",
    "        'classes': ';'.join(sorted(classes_present)) if classes_present else 'Background',\n",
    "        'has_annotations': 'Yes' if num_targets > 0 else 'No',\n",
    "        'video_path': str(img_path).replace(\"_videos_annotated\\\\images\", \"\").replace(\"_videos_annotated/images\", \"\").replace(\".jpg\", \".mp4\").replace(\".jpeg\", \".mp4\").replace(\".png\", \".mp4\").rsplit(\"_\", 1)[0] + \".mp4\",\n",
    "        'video_name': video_name,\n",
    "        'frame_number': frame_number\n",
    "    }\n",
    "    \n",
    "    dataset_rows.append(row)\n",
    "\n",
    "print(f\"\\n‚úì Collected metadata for {len(dataset_rows)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf4142",
   "metadata": {},
   "source": [
    "## 5. Create and Explore DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb2de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (10664, 10)\n",
      "\n",
      "Column names:\n",
      "['image_path', 'image_width', 'image_height', 'image_format', 'num_targets', 'classes', 'has_annotations', 'video_path', 'video_name', 'frame_number']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_format</th>\n",
       "      <th>num_targets</th>\n",
       "      <th>classes</th>\n",
       "      <th>has_annotations</th>\n",
       "      <th>video_path</th>\n",
       "      <th>video_name</th>\n",
       "      <th>frame_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  image_width  \\\n",
       "0  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "1  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "2  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "3  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "4  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "5  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "6  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "7  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "8  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "9  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "\n",
       "   image_height image_format  num_targets     classes has_annotations  \\\n",
       "0          1080         JPEG            0  Background              No   \n",
       "1          1080         JPEG            2       Plane             Yes   \n",
       "2          1080         JPEG            2       Plane             Yes   \n",
       "3          1080         JPEG            0  Background              No   \n",
       "4          1080         JPEG            2       Plane             Yes   \n",
       "5          1080         JPEG            2       Plane             Yes   \n",
       "6          1080         JPEG            0  Background              No   \n",
       "7          1080         JPEG            0  Background              No   \n",
       "8          1080         JPEG            0  Background              No   \n",
       "9          1080         JPEG            0  Background              No   \n",
       "\n",
       "                                          video_path  \\\n",
       "0  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "1  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "2  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "3  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "4  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "5  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "6  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "7  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "8  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "9  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "\n",
       "                                 video_name  frame_number  \n",
       "0  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf             0  \n",
       "1  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           124  \n",
       "2  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           149  \n",
       "3  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf            16  \n",
       "4  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           174  \n",
       "5  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           199  \n",
       "6  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           224  \n",
       "7  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf            24  \n",
       "8  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf            32  \n",
       "9  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf            48  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51a8ce",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca153bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total images: 10664\n",
      "\n",
      "Images with annotations: 892\n",
      "Images without annotations: 9772\n",
      "\n",
      "Annotation coverage: 8.4%\n",
      "\n",
      "Image dimensions:\n",
      "  Width  - Min: 1920, Max: 1920, Mean: 1920\n",
      "  Height - Min: 1080, Max: 1080, Mean: 1080\n",
      "\n",
      "Object count statistics:\n",
      "  Total targets: 1057\n",
      "  Mean targets per image: 0.10\n",
      "  Max targets in single image: 7\n",
      "  Images with targets distribution:\n",
      "    0 object(s): 9772 images\n",
      "    1 object(s): 776 images\n",
      "    2 object(s): 84 images\n",
      "    3 object(s): 21 images\n",
      "    4 object(s): 9 images\n",
      "    7 object(s): 2 images\n",
      "\n",
      "Unique videos: 959\n",
      "Unique classes: 9\n",
      "\n",
      "\n",
      "Validating image paths...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì All 10664 image paths are valid\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal images: {len(df)}\")\n",
    "print(f\"\\nImages with annotations: {(df['has_annotations'] == 'Yes').sum()}\")\n",
    "print(f\"Images without annotations: {(df['has_annotations'] == 'No').sum()}\")\n",
    "\n",
    "print(f\"\\nAnnotation coverage: {(df['has_annotations'] == 'Yes').sum() / len(df) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nImage dimensions:\")\n",
    "print(f\"  Width  - Min: {df['image_width'].min()}, Max: {df['image_width'].max()}, Mean: {df['image_width'].mean():.0f}\")\n",
    "print(f\"  Height - Min: {df['image_height'].min()}, Max: {df['image_height'].max()}, Mean: {df['image_height'].mean():.0f}\")\n",
    "\n",
    "print(f\"\\nObject count statistics:\")\n",
    "print(f\"  Total targets: {df['num_targets'].sum()}\")\n",
    "print(f\"  Mean targets per image: {df['num_targets'].mean():.2f}\")\n",
    "print(f\"  Max targets in single image: {df['num_targets'].max()}\")\n",
    "print(f\"  Images with targets distribution:\")\n",
    "for count in sorted(df['num_targets'].unique()):\n",
    "    freq = (df['num_targets'] == count).sum()\n",
    "    print(f\"    {count} object(s): {freq} images\")\n",
    "\n",
    "print(f\"\\nUnique videos: {df['video_name'].nunique()}\")\n",
    "print(f\"Unique classes: {df['classes'].nunique()}\")\n",
    "\n",
    "# Validate paths\n",
    "print(f\"\\n\\nValidating image paths...\")\n",
    "missing_count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    img_full_path = BASE_DIR / row['image_path']\n",
    "    if not img_full_path.exists():\n",
    "        print(f\"  ‚úó Missing: {row['image_path']}\")\n",
    "        missing_count += 1\n",
    "\n",
    "if missing_count == 0:\n",
    "    print(f\"  ‚úì All {len(df)} image paths are valid\")\n",
    "else:\n",
    "    print(f\"  ‚úó Found {missing_count} missing image files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7414523",
   "metadata": {},
   "source": [
    "## 7. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262991ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Classes by number of images containing them:\n",
      "  Background     : 9772 images,     0 total objects\n",
      "  Bat            :   46 images,    46 total objects\n",
      "  Bird           :  419 images,   458 total objects\n",
      "  Insect         :   41 images,    41 total objects\n",
      "  Other          :   15 images,    39 total objects\n",
      "  Plane          :  155 images,   234 total objects\n",
      "  Unknown        :  218 images,   239 total objects\n",
      "\n",
      "Total unique classes: 7\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "images_with_class = defaultdict(int)\n",
    "\n",
    "for classes_str in df['classes']:\n",
    "    if classes_str != 'none':\n",
    "        classes_list = classes_str.split(';')\n",
    "        for class_name in classes_list:\n",
    "            images_with_class[class_name] += 1\n",
    "\n",
    "# Count total objects by class\n",
    "for idx, row in df.iterrows():\n",
    "    if row['num_targets'] > 0:\n",
    "        label_path = LABELS_DIR / (Path(row['image_path']).stem + \".txt\")\n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        class_name = class_mapping.get(class_id, f\"Unknown_{class_id}\")\n",
    "                        class_counts[class_name] += 1\n",
    "\n",
    "print(f\"\\nClasses by number of images containing them:\")\n",
    "for class_name in sorted(images_with_class.keys()):\n",
    "    count = images_with_class[class_name]\n",
    "    total_objects = class_counts[class_name]\n",
    "    print(f\"  {class_name:15s}: {count:4d} images, {total_objects:5d} total objects\")\n",
    "\n",
    "print(f\"\\nTotal unique classes: {len(images_with_class)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261727b",
   "metadata": {},
   "source": [
    "## 8. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184fb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPORTING TO CSV\n",
      "============================================================\n",
      "\n",
      "‚úì Successfully exported dataset to:\n",
      "  /home/detect/DeTect_TaiwanBirds_VideoDetector/dataset/csvs/annotations.csv\n",
      "\n",
      "File size: 2566.7 KB\n",
      "Rows: 10664\n",
      "Columns: 10\n",
      "\n",
      "Sample CSV content (first 5 rows):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_format</th>\n",
       "      <th>num_targets</th>\n",
       "      <th>classes</th>\n",
       "      <th>has_annotations</th>\n",
       "      <th>video_path</th>\n",
       "      <th>video_name</th>\n",
       "      <th>frame_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>0</td>\n",
       "      <td>Background</td>\n",
       "      <td>No</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>2</td>\n",
       "      <td>Plane</td>\n",
       "      <td>Yes</td>\n",
       "      <td>/home/data/F2/videos/2025-05-14/images/A03_000...</td>\n",
       "      <td>A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  image_width  \\\n",
       "0  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "1  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "2  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "3  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "4  /home/data/F2/videos/2025-05-14/images/A03_000...         1920   \n",
       "\n",
       "   image_height image_format  num_targets     classes has_annotations  \\\n",
       "0          1080         JPEG            0  Background              No   \n",
       "1          1080         JPEG            2       Plane             Yes   \n",
       "2          1080         JPEG            2       Plane             Yes   \n",
       "3          1080         JPEG            0  Background              No   \n",
       "4          1080         JPEG            2       Plane             Yes   \n",
       "\n",
       "                                          video_path  \\\n",
       "0  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "1  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "2  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "3  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "4  /home/data/F2/videos/2025-05-14/images/A03_000...   \n",
       "\n",
       "                                 video_name  frame_number  \n",
       "0  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf             0  \n",
       "1  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           124  \n",
       "2  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           149  \n",
       "3  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf            16  \n",
       "4  A03_0000cfa6-1efa-350e-a754-5e23cfe9afaf           174  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export to CSV\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPORTING TO CSV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by image_path for consistency\n",
    "df_sorted = df.sort_values('image_path').reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "try:\n",
    "    df_sorted.to_csv(CSV_OUTPUT_PATH, index=False, encoding='utf-8')\n",
    "    print(f\"\\n‚úì Successfully exported dataset to:\")\n",
    "    print(f\"  {CSV_OUTPUT_PATH}\")\n",
    "    print(f\"\\nFile size: {CSV_OUTPUT_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"Rows: {len(df_sorted)}\")\n",
    "    print(f\"Columns: {len(df_sorted.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Error exporting to CSV: {e}\")\n",
    "\n",
    "# Display sample of CSV\n",
    "print(\"\\nSample CSV content (first 5 rows):\")\n",
    "print(\"-\" * 60)\n",
    "sample_df = pd.read_csv(CSV_OUTPUT_PATH).head(5)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f7526",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe6194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET GENERATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä SUMMARY REPORT\n",
      "------------------------------------------------------------\n",
      "\n",
      "Dataset Location:\n",
      "  üìÅ /home/detect/DeTect_TaiwanBirds_VideoDetector/dataset/csvs/annotations.csv\n",
      "\n",
      "Dataset Overview:\n",
      "  ‚Ä¢ Total images:           10,664\n",
      "  ‚Ä¢ Annotated images:       892 (8.4%)\n",
      "  ‚Ä¢ Unannotated images:     9,772\n",
      "  ‚Ä¢ Total targets:          1,057\n",
      "  ‚Ä¢ Unique classes:         7\n",
      "  ‚Ä¢ Unique videos:          959\n",
      "\n",
      "Image Specifications:\n",
      "  ‚Ä¢ Format(s):              JPEG\n",
      "  ‚Ä¢ Average size:           1920√ó1080 px\n",
      "\n",
      "CSV Columns:\n",
      "  image_path, image_width, image_height, image_format, num_targets, classes, has_annotations, video_path, video_name, frame_number\n",
      "\n",
      "Next Steps:\n",
      "  1. Use this CSV for training data preparation\n",
      "  2. Split dataset into train/validation/test sets\n",
      "  3. Preprocess images if needed\n",
      "  4. Configure your detector model with the metadata\n",
      "\n",
      "Note: Image paths are relative to the base directory\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úì Dataset CSV successfully created!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET GENERATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä SUMMARY REPORT\n",
    "{\"-\"*60}\n",
    "\n",
    "Dataset Location:\n",
    "  üìÅ {CSV_OUTPUT_PATH}\n",
    "\n",
    "Dataset Overview:\n",
    "  ‚Ä¢ Total images:           {len(df):,}\n",
    "  ‚Ä¢ Annotated images:       {(df['has_annotations'] == 'Yes').sum():,} ({(df['has_annotations'] == 'Yes').sum() / len(df) * 100:.1f}%)\n",
    "  ‚Ä¢ Unannotated images:     {(df['has_annotations'] == 'No').sum():,}\n",
    "  ‚Ä¢ Total targets:          {df['num_targets'].sum():,}\n",
    "  ‚Ä¢ Unique classes:         {len(images_with_class)}\n",
    "  ‚Ä¢ Unique videos:          {df['video_name'].nunique()}\n",
    "\n",
    "Image Specifications:\n",
    "  ‚Ä¢ Format(s):              {', '.join(df['image_format'].unique())}\n",
    "  ‚Ä¢ Average size:           {df['image_width'].mean():.0f}√ó{df['image_height'].mean():.0f} px\n",
    "\n",
    "CSV Columns:\n",
    "  {', '.join(df.columns.tolist())}\n",
    "\n",
    "Next Steps:\n",
    "  1. Use this CSV for training data preparation\n",
    "  2. Split dataset into train/validation/test sets\n",
    "  3. Preprocess images if needed\n",
    "  4. Configure your detector model with the metadata\n",
    "\n",
    "Note: Image paths are relative to the base directory\n",
    "{\"-\"*60}\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úì Dataset CSV successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607fa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataManagement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
